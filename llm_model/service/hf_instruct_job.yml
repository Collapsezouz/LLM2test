# smart_auto llm_model.service.hf_instruct_job predict_service
tasks:
  __load__:
  - auto_tasks.*.*
  - .hf_text_generation
  - .hf_tokenizer
  - .llm_redis_pip
  
trees:
  predict_service:
    __sibling__:
      worker_num: 1
      worker_mode: thread
      join_mode: object
    __flow__:
    - redis__pip.conn(redis_svr)~recv(pip_req)~@send
    - print.watch
    - hf_tokenizer.init(hf_model)~@hf_text_generation.encode_instruct(hf_model+predict_service)~encode(hf_model+predict_service)
    - cuda_tool.find_available_gpu(cuda_find_args)~@hf_text_generation.load_model(hf_model)~@hf_text_generation.generate(hf_model+predict_service)
    - redis__pip.conn$2(redis_svr)~send(pip_resp)
    cuda_tool.find_available_gpu:
      worker_mode: process

configs:
  hf_model:
    # model_path: /nas/tmp/phbsxgpt/chatllama_zh_stage1_v1.1
    # model_path: /home/app/expert-cpt/logs/chatllama_zh_stage1_v1.1
    model_name: "EleutherAI/pythia-70m"
    model_kwargs:
      # offload_folder: offload
      # revision: step2000
      device_map: auto
    # encode_opt:
    #   bos: True
    #   eos: False
    # decode_opt:
    #   bos: True
    #   eos: False
    # max_tokens: 512
    max_new_tokens: 200
    # pipeline_opt:
    #   return_tensors: pt
    instruct_version: 2

  predict_service:
    instruct_instruction_key: instruction
    instruct_input_key: input
    instruct_output_key: output
    input_text_key: text
    input_tokens_key: tokens
    output_tokens_key: pred_tokens
    output_text_key: pred_text
    streamer: text
    
  # predict_args:
  #   max_input_len: 256
  #   max_gen_len: 100
  #   send_step: 10
  #   # send_step: 1000
  #   prepend_input: True

  redis_svr:
    host: 10.2.223.230
    port: 6390
    password: 58d326d7e5e6e8739f51ddbe25be049fa4f75f9f
    db: 3
    redis_kwargs:
      socket_timeout: 90
      socket_connect_timeout: 60
      retry_on_timeout: 1
    
  pip_req:
    key: cedb_model.expert_cpt.job.pred_req
    redis_poll_interval: 30
    is_daemon: 1
  
  pip_resp:
    key: cedb_model.expert_cpt.job.pred_resp
    item_send_key: _send_queue
    item_ttl: 86400
    item_key: pred_text

  cuda_find_args:
    gpu_num: 1
    free_memory_ratio: 0.9
    # shuffle: False